{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "performance_metric.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aIDHBDse3aKp",
        "colab_type": "text"
      },
      "source": [
        "# Performance Metrics\n",
        "学习自[博客](https://blog.argcv.com/articles/1036.c) -- 准确率(Accuracy), 精确率(Precision), 召回率(Recall)和F1-Measure.\n",
        "\n",
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UGbsg2vS39-Z",
        "colab_type": "text"
      },
      "source": [
        "### 场景案例\n",
        "```c\n",
        "假如某个班级有男生 80 人, 女生20人, 共计 100 人. 目标是找出所有女生. 现在某人挑选出 50 个人, 其中 20 人是女生, 另外还错误的把 30 个男生也当作女生挑选出来了. \n",
        "```"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vzJWiBUZ4JFk",
        "colab_type": "text"
      },
      "source": [
        "## Accuracy\n",
        "\n",
        "accuracy 是**分类正确的人数**占**总人数**的比例。\n",
        "$$accuracy = \\frac{分类正确的人数}{总人数}$$\n",
        "\n",
        "在这个例子中，他把其中的70(20女+50男)判定正确了，总人数是100人，所以accuracy是70% (70/100)。\n",
        "\n",
        "### 局限性\n",
        "1. 不同类别样本比例不均匀时，占比大的类别往往成为影响accuracy的最主要因素 -- [评估指标的局限性](https://www.jianshu.com/p/79dd906e466c)。假设正样本个数为100个，总样本数为$10^7$，除去正样本，其余的都是副样本。正负样本比例约为$1 : 9,999,900 \\approx 1:10^7$，那么不论进来什么例子，我们都判定为负样本，此时accuracy已经达到了$99.999\\% = 9,999,900/10,000,000$\n",
        "\n",
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b80qVjuG6Y9J",
        "colab_type": "text"
      },
      "source": [
        "## Precision and Recall\n",
        "\n",
        "### 场景案例扩展\n",
        "基于之前的场景案例进行拓展，令：\n",
        "1. 正样本：女生\n",
        "2. 负样本：男生\n",
        "\n",
        "| | 女生(正样本) | 男生(负样本) |\n",
        "|-|------------|------------|\n",
        "|预测为女生| $TP(True\\ Positive)$<br>正确判定这个为女生| $FP(False\\ Positive)$<br> 错误判定这个为女生，原本为男生|\n",
        "|预测为男生| $FN(False\\ Negative)$<br>错误判定这个为男生，原本为女生| $TN(True\\ Negative)$<br>正确判定这个为男生 |\n",
        "\n",
        "\n",
        "| | 女生(正样本) | 男生(负样本) |\n",
        "|-|------------|------------|\n",
        "|预测为女生| $TP=20$ | $FP=30$ |\n",
        "|预测为男生| $FN=0$  | $TN=50$ |\n",
        "\n",
        "### Precision\n",
        "**精确率(presicion)**：又叫查准率，即$\\frac{预测为真实正样本}{所有真实正样本的个数}$。\n",
        "$$Precision = \\frac{TP}{TP+FP}$$\n",
        "\n",
        "### Recall\n",
        "**召回率(presicion)**：又叫查全率，即$\\frac{预测为真实正样本}{所有被预测为正例样本}$。\n",
        "$$Recall = \\frac{TP}{TP+FC}$$\n",
        "\n",
        "## 注意\n",
        "- precision和recall是互相影响的\n",
        "   * 理想状态下肯定是做到两者都高，但是一般情况下precision高，recall就低；precision低，recall就高。\n",
        "\n",
        "- **保证精准**：如果是做搜索，就是保证召回情况下提升准确率\n",
        "\n",
        "- **保证不漏报**：如果做疾病检测、反垃圾，则是保证准确率的条件下，提升召回。\n",
        "\n",
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZrLeM1er_RWY",
        "colab_type": "text"
      },
      "source": [
        "## F1-Measure\n",
        "\n",
        "F1值是precision和recall的调和平均。\n",
        "$$\\frac{2}{F_1} = \\frac{1}{P} + \\frac{1}{R}$$\n",
        "\n",
        "### 为什么引入调和平均\n",
        "因为Precision和Recall通常情况下相互制约，如果用算术平均无法体现这一点。例如Precision接近1，Recall接近于0时，此时算术平均为0.5，调和平均的F1值为0。\n",
        "\n",
        "可以理解为引入了惩罚机制，即：对于参与调和平均的所有对象，如果他们的值不均衡，那么即使其中某些值非常高，均值也不会高。\n",
        "\n",
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6Oakb-k4C34g",
        "colab_type": "text"
      },
      "source": [
        "## mAP (mean average precision)\n",
        "\n",
        "假设有两个主题，主题1有4个相关网页，主题2有5个相关网页。某系统对于主题1检索出4个相关网页，其rank分别为1, 2, 4, 7；对于主题2检索出3个相关网页，其rank分别为1,3,5。对于主题1，平均准确率为(1/1+2/2+3/4+4/7)/4=0.83。对于主题 2，平均准确率为(1/1+2/3+3/5+0+0)/5=0.45。则MAP=(0.83+0.45)/2=0.64。”\n",
        "\n",
        "也就是当前的precision值的平均.\n",
        "\n",
        "![mAP](https://github.com/Weizhuo-Zhang/leetcode_kick/blob/master/other_notebooks/pics/mAP.png?raw=1)\n",
        "\n",
        "VOC2010及以后的方法，对于Recall >= {0, 0.14, 0.29, 0.43, 0.57, 0.71, 1}，我们选取此时Percision的最大值：1, 1, 1, 0.5, 0.5, 0.5, 0。计算recall/precision下的面积：AP = (0.14-0)x1 + (0.29-0.14)x1 + (0.43-0.29)x0.5 + (0.57-0.43)x0.5 + (0.71-0.57)x0.5 + (1-0.71)x0 = 0.5\n",
        "计算出每个类别的AP以后，对于所有类别的AP取均值就得到mAP了\n",
        "\n",
        "```c\n",
        "rank=1  precision=1.00 and recall=0.14\n",
        "------------------------------\n",
        "rank=2  precision=1.00 and recall=0.29\n",
        "------------------------------\n",
        "rank=3  precision=0.66 and recall=0.29\n",
        "------------------------------\n",
        "rank=4  precision=0.50 and recall=0.29\n",
        "------------------------------\n",
        "rank=5  precision=0.40 and recall=0.29\n",
        "------------------------------\n",
        "rank=6  precision=0.50 and recall=0.43\n",
        "------------------------------\n",
        "rank=7  precision=0.43 and recall=0.43\n",
        "------------------------------\n",
        "rank=8  precision=0.38 and recall=0.43\n",
        "------------------------------\n",
        "rank=9  precision=0.44 and recall=0.57\n",
        "------------------------------\n",
        "rank=10 precision=0.50 and recall=0.71\n",
        "------------------------------\n",
        "```"
      ]
    }
  ]
}